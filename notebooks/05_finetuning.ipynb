{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14558068,"sourceType":"datasetVersion","datasetId":9298558}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Дообучение E5 на MIRACL\n\nFine-tuning multilingual-e5-base с использованием hard negatives.","metadata":{}},{"cell_type":"code","source":"!pip install pyarrow==18.1.0 -q\n!pip install datasets==2.14.0 sentence-transformers sentencepiece faiss-cpu rank-bm25 torch tqdm -q\n!pip install huggingface_hub gdown -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-22T18:38:00.506967Z","iopub.execute_input":"2026-01-22T18:38:00.507774Z","iopub.status.idle":"2026-01-22T18:38:18.947325Z","shell.execute_reply.started":"2026-01-22T18:38:00.507742Z","shell.execute_reply":"2026-01-22T18:38:18.946481Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 4.4.2 requires pyarrow>=21.0.0, but you have pyarrow 18.1.0 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.2/492.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.7 which is incompatible.\npathos 0.3.2 requires multiprocess>=0.70.16, but you have multiprocess 0.70.15 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Скачивание FAISS индекса\nimport gdown\n\nfile_id = \"1_z6Kup484-UKe4UxTTKRN2fzPmtYLsKn\"\nurl = f\"https://drive.google.com/uc?id={file_id}&export=download\"\noutput = \"dense_e5.faiss\"\n\ngdown.download(url, output, quiet=False)\nprint(f\"Индекс скачан: {output}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T13:59:25.548756Z","iopub.execute_input":"2026-01-22T13:59:25.548994Z","iopub.status.idle":"2026-01-22T13:59:40.932815Z","shell.execute_reply.started":"2026-01-22T13:59:25.548954Z","shell.execute_reply":"2026-01-22T13:59:40.932021Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1_z6Kup484-UKe4UxTTKRN2fzPmtYLsKn&export=download\nFrom (redirected): https://drive.google.com/uc?id=1_z6Kup484-UKe4UxTTKRN2fzPmtYLsKn&export=download&confirm=t&uuid=bbaccbfa-30e6-4b06-9397-e6882e0592f1\nTo: /kaggle/working/dense_e5.faiss\n100%|██████████| 1.66G/1.66G [00:13<00:00, 126MB/s] ","output_type":"stream"},{"name":"stdout","text":"Индекс скачан: dense_e5.faiss\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport json\nimport gzip\nimport random\nimport requests\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom collections import defaultdict\nfrom tqdm.notebook import tqdm\nfrom huggingface_hub import hf_hub_download, list_repo_files\nimport sentencepiece as spm\nfrom sentence_transformers import SentenceTransformer, InputExample, losses\nfrom torch.optim import AdamW\nfrom transformers import get_linear_schedule_with_warmup\nfrom torch.cuda.amp import autocast, GradScaler\nimport faiss\nimport gc\nimport time\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\nprint(f\"CUDA: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T13:59:57.741827Z","iopub.execute_input":"2026-01-22T13:59:57.742607Z","iopub.status.idle":"2026-01-22T14:00:29.069208Z","shell.execute_reply.started":"2026-01-22T13:59:57.742554Z","shell.execute_reply":"2026-01-22T14:00:29.068547Z"}},"outputs":[{"name":"stderr","text":"2026-01-22 14:00:12.429477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769090412.652774      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769090412.719484      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769090413.281241      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769090413.281273      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769090413.281276      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769090413.281278      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"CUDA: True\nGPU: Tesla T4\nVRAM: 15.8 GB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## 1. Загрузка данных","metadata":{}},{"cell_type":"code","source":"BASE_URL = \"https://huggingface.co/datasets/miracl/miracl/resolve/main/miracl-v1.0-ru/\"\n\ndef load_queries(split: str) -> dict:\n    url = f\"{BASE_URL}topics/topics.miracl-v1.0-ru-{split}.tsv\"\n    try:\n        response = requests.get(url, timeout=60)\n        response.raise_for_status()\n        queries = {}\n        for line in response.text.strip().split('\\n')[1:]:\n            parts = line.split('\\t')\n            if len(parts) >= 2:\n                queries[parts[0]] = parts[1]\n        return queries\n    except:\n        return {}\n\ndef load_qrels(split: str) -> dict:\n    url = f\"{BASE_URL}qrels/qrels.miracl-v1.0-ru-{split}.tsv\"\n    try:\n        response = requests.get(url, timeout=60)\n        response.raise_for_status()\n        qrels = defaultdict(lambda: {'positive': [], 'negative': []})\n        for line in response.text.strip().split('\\n'):\n            parts = line.split('\\t')\n            if len(parts) >= 4:\n                qid, doc_id, rel = parts[0], parts[2], int(parts[3])\n                key = 'positive' if rel > 0 else 'negative'\n                qrels[qid][key].append(doc_id)\n        return dict(qrels)\n    except:\n        return {}\n\ndef get_required_doc_ids(qrels_dict: dict) -> set:\n    doc_ids = set()\n    for q in qrels_dict.values():\n        doc_ids.update(q.get('positive', []))\n        doc_ids.update(q.get('negative', []))\n    return doc_ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:00:29.070347Z","iopub.execute_input":"2026-01-22T14:00:29.070887Z","iopub.status.idle":"2026-01-22T14:00:29.416080Z","shell.execute_reply.started":"2026-01-22T14:00:29.070862Z","shell.execute_reply":"2026-01-22T14:00:29.415278Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"dev_queries = load_queries('dev')\ndev_qrels = load_qrels('dev')\ntrain_queries = load_queries('train')\ntrain_qrels = load_qrels('train')\n\nall_qrels = {**dev_qrels, **train_qrels}\nrequired_doc_ids = get_required_doc_ids(all_qrels)\n\nprint(f\"Dev: {len(dev_queries)} запросов\")\nprint(f\"Train: {len(train_queries)} запросов\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:00:29.417055Z","iopub.execute_input":"2026-01-22T14:00:29.417309Z","iopub.status.idle":"2026-01-22T14:00:30.274428Z","shell.execute_reply.started":"2026-01-22T14:00:29.417286Z","shell.execute_reply":"2026-01-22T14:00:30.273615Z"}},"outputs":[{"name":"stdout","text":"Dev: 1251 запросов\nTrain: 4682 запросов\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"def load_corpus(target_docs: int = 500_000, seed: int = 42) -> tuple:\n    random.seed(seed)\n    \n    all_files = list_repo_files(\"miracl/miracl-corpus\", repo_type=\"dataset\")\n    jsonl_files = sorted([f for f in all_files if 'ru' in f and f.endswith('.jsonl.gz')])\n    docs_per_file = target_docs // len(jsonl_files)\n\n    corpus = {}\n    doc_ids = []\n    passages = []\n\n    for jsonl_file in tqdm(jsonl_files, desc=\"Загрузка корпуса\"):\n        try:\n            file_path = hf_hub_download(\n                repo_id=\"miracl/miracl-corpus\",\n                filename=jsonl_file,\n                repo_type=\"dataset\"\n            )\n\n            file_docs = []\n            required_docs = []\n\n            with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n                for line in f:\n                    if not line.strip():\n                        continue\n                    item = json.loads(line)\n                    doc = {\n                        'docid': item['docid'],\n                        'title': item['title'],\n                        'text': item['text'],\n                        'full_text': f\"{item['title']}. {item['text']}\"\n                    }\n                    \n                    if item['docid'] in required_doc_ids:\n                        required_docs.append(doc)\n                    else:\n                        file_docs.append(doc)\n\n            sample_size = min(docs_per_file, len(file_docs))\n            selected = random.sample(file_docs, sample_size) if file_docs else []\n            \n            for doc in selected + required_docs:\n                if doc['docid'] not in corpus:\n                    corpus[doc['docid']] = {\n                        'title': doc['title'],\n                        'text': doc['text'],\n                        'full_text': doc['full_text']\n                    }\n                    doc_ids.append(doc['docid'])\n                    passages.append(doc['full_text'])\n\n        except Exception as e:\n            print(f\"Ошибка: {e}\")\n\n    return corpus, doc_ids, passages\n\ncorpus, doc_ids, passages = load_corpus(target_docs=500_000)\nprint(f\"Загружено документов: {len(corpus):,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:00:31.581854Z","iopub.execute_input":"2026-01-22T14:00:31.582412Z","iopub.status.idle":"2026-01-22T14:02:45.096670Z","shell.execute_reply.started":"2026-01-22T14:00:31.582381Z","shell.execute_reply":"2026-01-22T14:02:45.093940Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Загрузка корпуса:   0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7482b52a700b426b8b82e797b8644ac1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-0.jsonl.gz:   0%|          | 0.00/100M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db748587de3a414aa907bfcce044473d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-1.jsonl.gz:   0%|          | 0.00/98.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6e8add26a694b82bd9c57636322a2a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-10.jsonl.gz:   0%|          | 0.00/75.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94242ada0d6c40cdb84b46d704563c49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-11.jsonl.gz:   0%|          | 0.00/78.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b17fecd85024b17a1ff49becc2d15df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-12.jsonl.gz:   0%|          | 0.00/76.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b267a92e33e4cefb75ffdfd5bf2de1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-13.jsonl.gz:   0%|          | 0.00/78.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ab9ea1691ac4a13bf8e50566633611c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-14.jsonl.gz:   0%|          | 0.00/78.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13c0d8631fad453b88fc395efe5cb691"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-15.jsonl.gz:   0%|          | 0.00/79.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e0d5e439e8848fd8bb03bb351a29ddc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-16.jsonl.gz:   0%|          | 0.00/81.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a357a9b876dd49dbb065873cce5b325d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-17.jsonl.gz:   0%|          | 0.00/82.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"243d42e5445c4cc08671729f3cd3dd2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-18.jsonl.gz:   0%|          | 0.00/81.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6a19c69405a4a12bd3257ae830da776"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-19.jsonl.gz:   0%|          | 0.00/6.75M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1b9b4faf80343799c9493ee8fb5cf0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-2.jsonl.gz:   0%|          | 0.00/90.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d185f3e3ebc4d5aab9489c6174fba29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-3.jsonl.gz:   0%|          | 0.00/89.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74f34f5bd519448da48c45f5c1566c9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-4.jsonl.gz:   0%|          | 0.00/82.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c1840f7ef7348a3b2b914a68bb957ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-5.jsonl.gz:   0%|          | 0.00/88.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d07e45068a8647dba8df73486ba80795"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-6.jsonl.gz:   0%|          | 0.00/81.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db88804eb7904ee8a6655483d2ead8fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-7.jsonl.gz:   0%|          | 0.00/80.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a336127c6f2b416fb9a4264dfa79c7de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-8.jsonl.gz:   0%|          | 0.00/74.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c6297474a894faca8ee45d64f45cbc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"miracl-corpus-v1.0-ru/docs-9.jsonl.gz:   0%|          | 0.00/73.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"166d1b144bec4bf3bae3473ded10d302"}},"metadata":{}},{"name":"stdout","text":"Загружено документов: 541,007\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## 2. Dense Retriever для майнинга негативов","metadata":{}},{"cell_type":"code","source":"MODEL_NAME = \"intfloat/multilingual-e5-base\"\nDENSE_INDEX_PATH = \"dense_e5.faiss\"\n\nclass DenseRetrieverE5:\n    def __init__(self, model_name: str):\n        print(f\"Загрузка модели: {model_name}\")\n        self.model = SentenceTransformer(model_name)\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        \n        if self.device == 'cuda':\n            self.model = self.model.to('cuda')\n            self.model.half()\n        \n        self.index = None\n        self.doc_ids = None\n        self.passages = None\n        self.dimension = None\n    \n    def _prepare_passage(self, text: str) -> str:\n        return f\"passage: {text}\"\n    \n    def _prepare_query(self, text: str) -> str:\n        return f\"query: {text}\"\n    \n    def fit(self, doc_ids: list, passages: list, batch_size: int = 128):\n        print(\"Построение индекса...\")\n        self.doc_ids = doc_ids\n        self.passages = passages\n        \n        with torch.no_grad():\n            sample = self.model.encode(\n                [self._prepare_passage(passages[0])],\n                convert_to_numpy=True,\n                normalize_embeddings=True\n            )\n        self.dimension = sample.shape[1]\n        \n        self.index = faiss.IndexFlatIP(self.dimension)\n        \n        for start_idx in tqdm(range(0, len(passages), batch_size), desc=\"Индексация\"):\n            end_idx = min(start_idx + batch_size, len(passages))\n            batch = [self._prepare_passage(p) for p in passages[start_idx:end_idx]]\n            \n            with torch.no_grad():\n                embeddings = self.model.encode(\n                    batch,\n                    batch_size=batch_size,\n                    show_progress_bar=False,\n                    convert_to_numpy=True,\n                    normalize_embeddings=True\n                )\n            self.index.add(embeddings.astype('float32'))\n            \n            if (start_idx // batch_size) % 50 == 0:\n                gc.collect()\n                torch.cuda.empty_cache()\n        \n        print(f\"Индекс построен: {len(doc_ids):,} документов\")\n    \n    def search(self, query: str, top_k: int = 10) -> list:\n        prepared_query = self._prepare_query(query)\n        \n        with torch.no_grad():\n            query_emb = self.model.encode(\n                [prepared_query],\n                convert_to_numpy=True,\n                normalize_embeddings=True\n            ).astype('float32')\n        \n        scores, indices = self.index.search(query_emb, top_k)\n        \n        return [{\n            'doc_id': self.doc_ids[idx],\n            'score': float(score),\n            'passage': self.passages[idx]\n        } for idx, score in zip(indices[0], scores[0])]\n    \n    def save_index(self, path: str):\n        faiss.write_index(self.index, path)\n        print(f\"Индекс сохранён: {path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:02:45.106291Z","iopub.execute_input":"2026-01-22T14:02:45.108192Z","iopub.status.idle":"2026-01-22T14:02:45.142704Z","shell.execute_reply.started":"2026-01-22T14:02:45.107703Z","shell.execute_reply":"2026-01-22T14:02:45.141873Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Загрузка индекса для майнинга hard negatives\ndense_retriever = DenseRetrieverE5(MODEL_NAME)\ndense_retriever.index = faiss.read_index(DENSE_INDEX_PATH)\ndense_retriever.doc_ids = doc_ids\ndense_retriever.passages = passages\ndense_retriever.dimension = dense_retriever.index.d\n\nprint(f\"Dense индекс загружен: {dense_retriever.index.ntotal:,} документов\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:02:45.143548Z","iopub.execute_input":"2026-01-22T14:02:45.145304Z","iopub.status.idle":"2026-01-22T14:02:53.204895Z","shell.execute_reply.started":"2026-01-22T14:02:45.145264Z","shell.execute_reply":"2026-01-22T14:02:53.204105Z"}},"outputs":[{"name":"stdout","text":"Загрузка модели: intfloat/multilingual-e5-base\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2292000aab64ff588abba1310e8ac7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"421934018f3c4bd58fa74c28c3a6d500"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"523040abb7034d668b9695b97e3e7493"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28a081bc7c09496b95b3ed519590e4b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8229e3f0ebec478d924024fedc53c312"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8fdc4ed129e469799135d43c277d299"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de992076e72740cc9f530e9b9061e959"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b74ea935ec844c898adc21d9195df147"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5932110627a0499b9eb4f2aec9753ac1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13212a4e621c45228a063bd25a1c7590"}},"metadata":{}},{"name":"stdout","text":"Dense индекс загружен: 541,007 документов\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## 3. Подготовка обучающих данных","metadata":{}},{"cell_type":"code","source":"def prepare_training_data(queries, qrels, corpus, retriever):\n    \"\"\"Hard negatives из retriever + random negatives\"\"\"\n    training_data = []\n    corpus_keys = list(corpus.keys())\n    \n    valid_queries = {k: v for k, v in queries.items() if k in qrels}\n    \n    for qid, query_text in tqdm(valid_queries.items(), desc=\"Подготовка данных\"):\n        pos_ids = [pid for pid in qrels[qid]['positive'] if pid in corpus]\n        if not pos_ids:\n            continue\n        \n        # Hard negatives\n        hard_negs = []\n        try:\n            hits = retriever.search(query_text, top_k=20)\n            hard_negs = [h['doc_id'] for h in hits \n                        if h['doc_id'] not in pos_ids and h['doc_id'] in corpus]\n        except:\n            pass\n        \n        # Random negatives\n        random_negs = []\n        while len(random_negs) < 3:\n            rid = random.choice(corpus_keys)\n            if rid not in pos_ids and rid not in hard_negs:\n                random_negs.append(rid)\n        \n        negatives = hard_negs[:5] + random_negs\n        \n        if negatives:\n            for pid in pos_ids:\n                training_data.append({\n                    'query': query_text,\n                    'positive': corpus[pid]['full_text'],\n                    'negatives': [corpus[n]['full_text'] for n in negatives]\n                })\n    \n    print(f\"Примеров: {len(training_data):,}\")\n    return training_data\n\ntraining_data = prepare_training_data(train_queries, train_qrels, corpus, dense_retriever)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:02:53.206418Z","iopub.execute_input":"2026-01-22T14:02:53.206684Z","iopub.status.idle":"2026-01-22T14:14:20.419724Z","shell.execute_reply.started":"2026-01-22T14:02:53.206660Z","shell.execute_reply":"2026-01-22T14:14:20.418943Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Подготовка данных:   0%|          | 0/4682 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a93c2f291f264faf94fd0a9200a1db78"}},"metadata":{}},{"name":"stdout","text":"Примеров: 9,999\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"class E5Dataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        item = self.data[idx]\n        \n        # Префиксы для E5\n        query = f\"query: {item['query']}\"\n        pos = f\"passage: {item['positive']}\"\n        \n        # Случайные 3 негатива\n        negs = item['negatives'].copy()\n        random.shuffle(negs)\n        selected_negs = [f\"passage: {n}\" for n in negs[:3]]\n        \n        return InputExample(texts=[query, pos] + selected_negs)\n\ntrain_dataset = E5Dataset(training_data)\nprint(f\"Dataset: {len(train_dataset):,} примеров\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:14:20.420684Z","iopub.execute_input":"2026-01-22T14:14:20.420936Z","iopub.status.idle":"2026-01-22T14:14:20.427064Z","shell.execute_reply.started":"2026-01-22T14:14:20.420912Z","shell.execute_reply":"2026-01-22T14:14:20.426308Z"}},"outputs":[{"name":"stdout","text":"Dataset: 9,999 примеров\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## 4. Обучение","metadata":{}},{"cell_type":"code","source":"OUTPUT_PATH = \"finetuned_e5\"\nBATCH_SIZE = 24\nEPOCHS = 1\nMAX_SEQ_LENGTH = 160\nLEARNING_RATE = 2e-5\n\ngc.collect()\ntorch.cuda.empty_cache()\n\nprint(f\"Загрузка модели: {MODEL_NAME}\")\nmodel = SentenceTransformer(MODEL_NAME)\nmodel.max_seq_length = MAX_SEQ_LENGTH\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ntrain_loss = losses.MultipleNegativesRankingLoss(model)\n\ntrain_dataloader = DataLoader(\n    train_dataset, \n    batch_size=BATCH_SIZE, \n    shuffle=True, \n    drop_last=True,\n    num_workers=0,\n    collate_fn=model.smart_batching_collate\n)\n\noptimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\ntotal_steps = len(train_dataloader) * EPOCHS\nwarmup_steps = int(total_steps * 0.1)\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=warmup_steps, \n    num_training_steps=total_steps\n)\n\nscaler = GradScaler()\n\nprint(f\"\\nКонфигурация:\")\nprint(f\"  Device: {device}\")\nprint(f\"  Batch: {BATCH_SIZE}\")\nprint(f\"  Steps: {total_steps}\")\nprint(f\"  LR: {LEARNING_RATE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:14:20.427930Z","iopub.execute_input":"2026-01-22T14:14:20.428184Z","iopub.status.idle":"2026-01-22T14:14:23.400739Z","shell.execute_reply.started":"2026-01-22T14:14:20.428162Z","shell.execute_reply":"2026-01-22T14:14:23.399939Z"}},"outputs":[{"name":"stdout","text":"Загрузка модели: intfloat/multilingual-e5-base\n\nКонфигурация:\n  Device: cuda\n  Batch: 24\n  Steps: 416\n  LR: 2e-05\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(f\"\\nСтарт обучения: {time.strftime('%H:%M:%S')}\")\nmodel.train()\nstart_time = time.time()\n\nfor epoch in range(EPOCHS):\n    epoch_loss = 0.0\n    pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n    \n    for step, (batch_features, labels) in enumerate(pbar):\n        features = [{k: v.to(device) for k, v in component.items()} \n                   for component in batch_features]\n        \n        optimizer.zero_grad()\n        \n        with autocast():\n            loss_value = train_loss(features, labels)\n        \n        scaler.scale(loss_value).backward()\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        scaler.step(optimizer)\n        scaler.update()\n        scheduler.step()\n        \n        epoch_loss += loss_value.item()\n        \n        if step % 10 == 0:\n            pbar.set_postfix({'loss': f\"{loss_value.item():.4f}\"})\n        \n        if step % 50 == 0:\n            torch.cuda.empty_cache()\n\n    avg_loss = epoch_loss / len(train_dataloader)\n    print(f\"Epoch {epoch+1}: avg_loss = {avg_loss:.4f}\")\n\nprint(f\"\\nОбучение завершено за {(time.time()-start_time)/60:.1f} мин\")\n\nmodel.save(OUTPUT_PATH)\nprint(f\"Модель сохранена: {OUTPUT_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:14:23.401801Z","iopub.execute_input":"2026-01-22T14:14:23.402177Z","iopub.status.idle":"2026-01-22T14:21:08.550858Z","shell.execute_reply.started":"2026-01-22T14:14:23.402151Z","shell.execute_reply":"2026-01-22T14:21:08.550165Z"}},"outputs":[{"name":"stdout","text":"\nСтарт обучения: 14:14:23\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/1:   0%|          | 0/416 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c03b343cccdd4aa7bbb799285fcc64e2"}},"metadata":{}},{"name":"stdout","text":"Epoch 1: avg_loss = 0.8331\n\nОбучение завершено за 6.7 мин\nМодель сохранена: finetuned_e5\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## 5. Создание нового Retriever","metadata":{}},{"cell_type":"code","source":"# Очистка памяти\ndel model, train_loss, optimizer, scheduler\ngc.collect()\ntorch.cuda.empty_cache()\n\n# Новый retriever с дообученной моделью\ntrained_retriever = DenseRetrieverE5(model_name=OUTPUT_PATH)\ntrained_retriever.fit(doc_ids, passages, batch_size=64)\ntrained_retriever.save_index(\"trained_e5.faiss\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:21:08.552049Z","iopub.execute_input":"2026-01-22T14:21:08.552694Z","iopub.status.idle":"2026-01-22T14:41:48.278265Z","shell.execute_reply.started":"2026-01-22T14:21:08.552666Z","shell.execute_reply":"2026-01-22T14:41:48.277465Z"}},"outputs":[{"name":"stdout","text":"Загрузка модели: finetuned_e5\nПостроение индекса...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Индексация:   0%|          | 0/8454 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bafeeeab664d452aba8879162437c5b3"}},"metadata":{}},{"name":"stdout","text":"Индекс построен: 541,007 документов\nИндекс сохранён: trained_e5.faiss\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## 6. Оценка","metadata":{}},{"cell_type":"code","source":"def evaluate(retriever, queries: dict, qrels: dict, ks: list = [1, 5, 10, 20, 100]) -> dict:\n    metrics = defaultdict(list)\n    indexed = set(retriever.doc_ids)\n    \n    for qid, text in tqdm(queries.items(), desc=\"Оценка\"):\n        if qid not in qrels:\n            continue\n        \n        relevant = [d for d in qrels[qid]['positive'] if d in indexed]\n        if not relevant:\n            continue\n        \n        results = retriever.search(text, top_k=max(ks))\n        retrieved = [r['doc_id'] for r in results]\n        \n        for k in ks:\n            hit = len(set(retrieved[:k]) & set(relevant))\n            metrics[f'Recall@{k}'].append(hit / len(relevant))\n        \n        for rank, doc_id in enumerate(retrieved, 1):\n            if doc_id in set(relevant):\n                metrics['MRR'].append(1.0 / rank)\n                break\n        else:\n            metrics['MRR'].append(0.0)\n        \n        dcg = sum(1.0/np.log2(i+2) for i, d in enumerate(retrieved[:10]) if d in set(relevant))\n        idcg = sum(1.0/np.log2(i+2) for i in range(min(10, len(relevant))))\n        metrics['NDCG@10'].append(dcg / idcg if idcg > 0 else 0)\n    \n    return {k: np.mean(v) for k, v in metrics.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:41:48.280122Z","iopub.execute_input":"2026-01-22T14:41:48.280375Z","iopub.status.idle":"2026-01-22T14:41:48.288286Z","shell.execute_reply.started":"2026-01-22T14:41:48.280352Z","shell.execute_reply":"2026-01-22T14:41:48.287739Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"trained_metrics = evaluate(trained_retriever, dev_queries, dev_qrels)\n\nbaseline = {'MRR': 0.7935, 'NDCG@10': 0.7479, 'Recall@10': 0.8641}\n\nprint(\"\\nСравнение результатов:\")\nprint(\"-\" * 45)\nprint(f\"{'Метрика':<12} {'Baseline':<12} {'Fine-tuned':<12} {'Δ':<10}\")\nprint(\"-\" * 45)\nfor m in ['MRR', 'NDCG@10', 'Recall@10']:\n    b = baseline.get(m, 0)\n    t = trained_metrics.get(m, 0)\n    d = t - b\n    sign = \"+\" if d > 0 else \"\"\n    status = \"✓\" if d > 0 else \"\"\n    print(f\"{m:<12} {b:<12.4f} {t:<12.4f} {sign}{d:.4f} {status}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:41:48.288954Z","iopub.execute_input":"2026-01-22T14:41:48.289262Z","iopub.status.idle":"2026-01-22T14:44:52.336979Z","shell.execute_reply.started":"2026-01-22T14:41:48.289238Z","shell.execute_reply":"2026-01-22T14:44:52.336225Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Оценка:   0%|          | 0/1251 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30d48b7a33ea43eabd93f85f34dbfce7"}},"metadata":{}},{"name":"stdout","text":"\nСравнение результатов:\n---------------------------------------------\nМетрика      Baseline     Fine-tuned   Δ         \n---------------------------------------------\nMRR          0.7935       0.8061       +0.0126 ✓\nNDCG@10      0.7479       0.7631       +0.0152 ✓\nRecall@10    0.8641       0.8704       +0.0063 ✓\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 7. Тестирование","metadata":{}},{"cell_type":"code","source":"test_questions = [\n    \"Кто такой Юрий Гагарин?\",\n    \"Столица России\",\n    \"Кто написал Войну и мир?\"\n]\n\nfor q in test_questions:\n    print(f\"\\n{q}\")\n    result = trained_retriever.search(q, top_k=1)[0]\n    print(f\"  [{result['score']:.4f}] {result['passage'][:120]}...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:44:52.338012Z","iopub.execute_input":"2026-01-22T14:44:52.338457Z","iopub.status.idle":"2026-01-22T14:44:52.776957Z","shell.execute_reply.started":"2026-01-22T14:44:52.338432Z","shell.execute_reply":"2026-01-22T14:44:52.776429Z"}},"outputs":[{"name":"stdout","text":"\nКто такой Юрий Гагарин?\n  [0.5232] Гагарин, Григорий Григорьевич (1945). Князь Григо́рий Григо́рьевич Гага́рин (род. 2 октября 1945, Вильжюиф, Франция) — п...\n\nСтолица России\n  [0.6927] Столицы России. Столица России — главный город государства, политический и административный центр страны. На протяжении ...\n\nКто написал Войну и мир?\n  [0.6274] Война и мир. Замысел эпопеи формировался задолго до начала работы над тем текстом, который известен под названием «Война...\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## 8. Сохранение результатов","metadata":{}},{"cell_type":"code","source":"results = {\n    'model': OUTPUT_PATH,\n    'baseline_metrics': baseline,\n    'trained_metrics': trained_metrics,\n    'improvement': {\n        'MRR': trained_metrics['MRR'] - baseline['MRR'],\n        'Recall@10': trained_metrics['Recall@10'] - baseline['Recall@10']\n    }\n}\n\nwith open('finetuning_results.json', 'w', encoding='utf-8') as f:\n    json.dump(results, f, ensure_ascii=False, indent=2)\n\nprint(\"Результаты сохранены: finetuning_results.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:44:52.778016Z","iopub.execute_input":"2026-01-22T14:44:52.778261Z","iopub.status.idle":"2026-01-22T14:44:52.783794Z","shell.execute_reply.started":"2026-01-22T14:44:52.778236Z","shell.execute_reply":"2026-01-22T14:44:52.782992Z"}},"outputs":[{"name":"stdout","text":"Результаты сохранены: finetuning_results.json\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"print(f\"\"\"\nИтоги дообучения E5:\n\nКонфигурация:\n  Базовая модель: {MODEL_NAME}\n  Batch size: {BATCH_SIZE}\n  Epochs: {EPOCHS}\n  Learning rate: {LEARNING_RATE}\n  Примеров: {len(training_data):,}\n\nРезультаты (dev):\n  MRR:       {baseline['MRR']:.4f} → {trained_metrics['MRR']:.4f}\n  Recall@10: {baseline['Recall@10']:.4f} → {trained_metrics['Recall@10']:.4f}\n  NDCG@10:   {baseline['NDCG@10']:.4f} → {trained_metrics['NDCG@10']:.4f}\n\nФайлы:\n  {OUTPUT_PATH}/ - дообученная модель\n  trained_e5.faiss - FAISS индекс\n\"\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-22T14:44:52.784693Z","iopub.execute_input":"2026-01-22T14:44:52.784966Z","iopub.status.idle":"2026-01-22T14:44:52.796432Z","shell.execute_reply.started":"2026-01-22T14:44:52.784935Z","shell.execute_reply":"2026-01-22T14:44:52.795920Z"}},"outputs":[{"name":"stdout","text":"\nИтоги дообучения E5:\n\nКонфигурация:\n  Базовая модель: intfloat/multilingual-e5-base\n  Batch size: 24\n  Epochs: 1\n  Learning rate: 2e-05\n  Примеров: 9,999\n\nРезультаты (dev):\n  MRR:       0.7935 → 0.8061\n  Recall@10: 0.8641 → 0.8704\n  NDCG@10:   0.7479 → 0.7631\n\nФайлы:\n  finetuned_e5/ - дообученная модель\n  trained_e5.faiss - FAISS индекс\n\n","output_type":"stream"}],"execution_count":18}]}